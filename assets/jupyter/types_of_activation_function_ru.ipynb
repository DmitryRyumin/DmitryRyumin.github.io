{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Версия Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подавление предупреждений\n",
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import jupyterlab as jlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Версии необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Библиотека</th>\n",
       "      <th>Версия</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>№</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torch</td>\n",
       "      <td>2.2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NumPy</td>\n",
       "      <td>1.26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pandas</td>\n",
       "      <td>2.2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JupyterLab</td>\n",
       "      <td>4.2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Библиотека  Версия\n",
       "№                    \n",
       "1       Torch   2.2.2\n",
       "2       NumPy  1.26.4\n",
       "3      Pandas   2.2.2\n",
       "4  JupyterLab   4.2.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "packages = [\n",
    "    \"Torch\", \"NumPy\", \"Pandas\", \"JupyterLab\",\n",
    "]\n",
    "\n",
    "package_objects = [\n",
    "    torch, np, pd, jlab\n",
    "]\n",
    "\n",
    "versions = [obj.__version__ for obj in package_objects]\n",
    "\n",
    "pkgs = {\"Библиотека\": packages, \"Версия\": versions}\n",
    "df_pkgs = pd.DataFrame(data = pkgs)\n",
    "df_pkgs.index.name = \"№\"\n",
    "df_pkgs.index += 1\n",
    "\n",
    "display(df_pkgs)\n",
    "\n",
    "path_to_reqs = \".\"\n",
    "reqs_name = \"requirements.txt\"\n",
    "\n",
    "def get_packages_and_versions():\n",
    "    \"\"\"Генерация строк с библиотеками и их версиями в формате: библиотека==версия\"\"\"\n",
    "    \n",
    "    for package, version in zip(packages, versions):\n",
    "        yield f\"{package.lower()}=={version}\\n\"\n",
    "\n",
    "with open(os.path.join(path_to_reqs, reqs_name), \"w\", encoding = \"utf-8\") as f:\n",
    "    f.writelines(get_packages_and_versions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU (Rectified Linear Unit)\n",
    "\n",
    "> Замена всех отрицательных значений на 0, при этом положительные значения остаются без изменений\n",
    "\n",
    "$$\n",
    "\\text{ReLU}(x) =\n",
    "\\begin{cases} \n",
    "0 & \\text{если } x \\leq 0 \\\\\n",
    "x & \\text{если } x > 0 \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([0.0000, 1.1458])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта ReLU\n",
    "g = nn.ReLU()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации ReLU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU (Exponential Linear Unit)\n",
    "\n",
    "> Преобразование отрицательных значений на $\\alpha (\\exp(x) - 1)$, делающее их менее агрессивными по сравнению с *ReLU*, с сохранением положительных значений без изменений\n",
    "\n",
    "$$\n",
    "\\text{ELU}(x) = \n",
    "\\begin{cases} \n",
    "x & \\text{если } x > 0 \\\\\n",
    "\\alpha (\\exp(x) - 1) & \\text{если } x \\leq 0 \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-0.9049,  1.1458])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта ELU\n",
    "g = nn.ELU(alpha = 1.0)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации ELU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PReLU (Parametric ReLU)\n",
    "\n",
    "> Преобразование значений, оставляя положительные значения без изменений, и умножая отрицательные значения на обучаемый параметр $\\alpha$\n",
    "> $\\text{где } \\alpha \\text{ — обучаемый параметр}$\n",
    "\n",
    "$$\n",
    "\\text{PReLU}(x) = \n",
    "\\begin{cases} \n",
    "x & \\text{если } x \\geq 0 \\\\\n",
    "\\alpha x & \\text{если } x < 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([[ 0.6465, -0.9450, -0.5559, -1.5250],\n",
      "        [-1.4968, -1.1030,  0.5872, -0.7036]])\n",
      "Выходные данные: tensor([[ 0.6465, -0.2362, -0.1390, -0.3812],\n",
      "        [-0.3742, -0.2758,  0.5872, -0.1759]], grad_fn=<PreluKernelBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта PReLU\n",
    "g = nn.PReLU(num_parameters = 4, init = 0.25)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([\n",
    "    [ 0.6465, -0.9450, -0.5559, -1.5250],\n",
    "    [-1.4968, -1.1030,  0.5872, -0.7036]\n",
    "]) # torch.randn(2, 4)\n",
    "\n",
    "# Применение функции активации PReLU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeakyReLU\n",
    "\n",
    "> Преобразование значений, оставляя положительные значения без изменений, и умножая отрицательные значения на коэффициент $\\alpha$,\n",
    "> $\\text{где } \\alpha = \\text{negative_slope}$\n",
    "\n",
    "$$\n",
    "\\text{LeakyReLU}(x) = \n",
    "\\begin{cases} \n",
    "x & \\text{если } x \\geq 0 \\\\\n",
    "\\alpha x & \\text{если } x < 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-0.0235,  1.1458])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта LeakyReLU\n",
    "g = nn.LeakyReLU(negative_slope = 0.01)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации LeakyReLU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU6\n",
    "\n",
    "> Преобразование значений меньше 0 в 0, больше 6 в 6, и оставляя остальные значения без изменений\n",
    "\n",
    "$$\n",
    "\\text{ReLU6}(x) = \\min(\\max(0, x), 6)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458,  6.2345])\n",
      "Выходные данные: tensor([0.0000, 1.1458, 6.0000])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта ReLU6\n",
    "g = nn.ReLU6()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458, 6.2345]) # torch.randn(3)\n",
    "\n",
    "# Применение функции активации ReLU6 к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RReLU (Randomized Leaky ReLU)\n",
    "\n",
    "> Преобразование значений, оставляя положительные значения без изменений, и умножая отрицательные значения на случайно выбранный коэффициент $\\alpha$\n",
    "\n",
    "$$\n",
    "\\text{RReLU}(x) = \n",
    "\\begin{cases} \n",
    "x & \\text{если } x \\geq 0 \\\\\n",
    "\\alpha x & \\text{если } x < 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458,  6.2345])\n",
      "Выходные данные: tensor([-0.7273,  1.1458,  6.2345])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта RReLU\n",
    "g = nn.RReLU(lower = 0.125, upper = 0.333)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458, 6.2345]) # torch.randn(3)\n",
    "\n",
    "# Применение функции активации RReLU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU (Scaled Exponential Linear Unit)\n",
    "\n",
    "> Преобразование значений, сохраняя положительные без изменений и масштабируя их параметром $scale$, а отрицательные параметрами $\\alpha$ и $scale$\n",
    "> $\\text{где } \\text{scale} \\approx 1.0507 \\text{ и } \\alpha \\approx 1.6733$\n",
    "\n",
    "$$\n",
    "\\text{SELU}(x) = \\text{scale} \\times (\\max(0, x) + \\min(0, \\alpha \\times (\\exp(x) - 1)))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-1.5909,  1.2039])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта SELU\n",
    "g = nn.SELU()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации SELU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELU (Continuously Differentiable Exponential Linear Unit)\n",
    "\n",
    "> Преобразование отрицательных значений с использованием экспоненциальной функции и параметра $\\alpha$ и сохраняя положительные значения без изменений\n",
    "\n",
    "$$\n",
    "\\text{CELU}(x) = \n",
    "\\begin{cases} \n",
    "x & \\text{если } x \\geq 0 \\\\\n",
    "\\alpha \\times (\\exp(x / \\alpha) - 1) & \\text{если } x < 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-0.9049,  1.1458])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта CELU\n",
    "g = nn.CELU(alpha = 1.0)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации CELU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GELU (Gaussian Error Linear Unit)\n",
    "\n",
    "> Преобразование значений, приближая их к гауссовому распределению\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = x \\times \\Phi(x) \\quad \\text{где } \\Phi(x) \\text{ - функция кумулятивного распределения для нормального распределения (}approximate=none\\text{)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{GELU}(x) = 0.5 \\times x \\times \\left(1 + \\tanh\\left(\\sqrt{\\frac{2}{\\pi}} \\left(x + 0.044715 x^3\\right)\\right)\\right) \\quad \\text{где } approximate=tanh\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-0.0219,  1.0015])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта GELU\n",
    "g = nn.GELU(approximate = \"none\") # none | tanh\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации GELU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid\n",
    "\n",
    "> Преобразование значений в диапазоне от 0 до 1\n",
    "\n",
    "$$\n",
    "\\text{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([0.0869, 0.7587])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Sigmoid\n",
    "g = nn.Sigmoid()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации Sigmoid к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SiLU (Sigmoid Linear Unit)\n",
    "\n",
    "> Комбинирование значений $x$ с их сигмоидными преобразованиями $\\sigma(x) = \\frac{1}{1 + e^{-x}}$\n",
    "\n",
    "$$\n",
    "\\text{SiLU}(x) = x \\times \\sigma(x) \\quad \\text{где } \\sigma(x) = \\frac{1}{1 + e^{-x}} \\text{ - сигмоидная функция}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-0.2043,  0.8694])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта SiLU\n",
    "g = nn.SiLU()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации SiLU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogSigmoid\n",
    "\n",
    "> Преобразование значений с помощью логарифма сигмоидной функции\n",
    "\n",
    "$$\n",
    "\\text{LogSigmoid}(x) = \\log \\left( \\frac{1}{1 + \\exp(-x)} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-2.4435, -0.2761])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта LogSigmoid\n",
    "g = nn.LogSigmoid()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации LogSigmoid к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardsigmoid\n",
    "\n",
    "> Преобразование значений, которые меньше или равны $−3$, в 0, значения, которые больше или равны $3$, в 1, и значения между \n",
    "$−3$ и $3$, с помощью функции $\\frac{x}{6} + 0.5$\n",
    "\n",
    "$$\n",
    "\\text{Hardsigmoid}(x) = \n",
    "\\begin{cases} \n",
    "0 & \\text{если } x \\leq -3 \\\\\n",
    "1 & \\text{если } x \\geq 3 \\\\\n",
    "\\frac{x}{6} + 0.5 & \\text{иначе}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-3.3526,  3.1458, -2.0256,  1.7843])\n",
      "Выходные данные: tensor([0.0000, 1.0000, 0.1624, 0.7974])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Hardsigmoid\n",
    "g = nn.Hardsigmoid()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-3.3526, 3.1458, -2.0256, 1.7843]) # torch.randn(4)\n",
    "\n",
    "# Применение функции активации Hardsigmoid к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanh\n",
    "\n",
    "> Преобразование значений в диапазоне от -1 до 1\n",
    "\n",
    "$$\n",
    "\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-0.9821,  0.8164])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Tanh\n",
    "g = nn.Tanh()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации Tanh к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tanhshrink\n",
    "\n",
    "> Преобразование значений, где из самих входных значений вычитается гиперболический $tanh$\n",
    "\n",
    "$$\n",
    "\\text{Tanhshrink}(x) = x - \\tanh(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-1.3705,  0.3294])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Tanhshrink\n",
    "g = nn.Tanhshrink()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации Tanhshrink к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardtanh\n",
    "\n",
    "> Преобразование значений, которые меньше $min\\_val$, в $min\\_val$, которые больше $max\\_val$, в $max\\_val$,\n",
    "> и оставляя значения между $min\\_val$ и $max\\_val$ без изменений\n",
    "\n",
    "$$\n",
    "\\text{HardTanh}(x) = \n",
    "\\begin{cases} \n",
    "min\\_val & \\text{если } x < min\\_val \\\\\n",
    "max\\_val & \\text{если } x > max\\_val \\\\\n",
    "x & \\text{иначе}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-1.1383,  1.1630, -0.8715,  0.7228])\n",
      "Выходные данные: tensor([-1.0000,  1.0000, -0.8715,  0.7228])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Hardtanh\n",
    "g = nn.Hardtanh(min_val = -1.0, max_val = 1.0)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-1.1383, 1.1630, -0.8715, 0.7228]) # torch.randn(4)\n",
    "\n",
    "# Применение функции активации Hardtanh к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardshrink\n",
    "\n",
    "> Преобразование значений, которые находятся между $-\\lambda$ и $\\lambda$ включительно, в 0, и оставляя значения, которые меньше $-\\lambda$ или больше $\\lambda$, без изменений\n",
    "\n",
    "$$\n",
    "\\text{HardShrink}(x) = \n",
    "\\begin{cases} \n",
    "x & \\text{если } x > \\lambda \\\\\n",
    "x & \\text{если } x < -\\lambda \\\\\n",
    "0 & \\text{иначе}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-2.3526,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Hardshrink\n",
    "g = nn.Hardshrink(lambd = 1.1458)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации Hardshrink к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hardswish\n",
    "\n",
    "> Преобразование значений, которые меньше или равны $−3$, в 0, значения, которые больше или равны $3$, остаются без изменений,\n",
    "> и значения между $−3$ и $3$ преобразуются с помощью функции $x \\left(\\frac{x+3}{6}\\right)$\n",
    "\n",
    "$$\n",
    "\\text{Hardswish}(x) = \n",
    "\\begin{cases} \n",
    "0 & \\text{если } x \\leq -3 \\\\\n",
    "x & \\text{если } x \\geq 3 \\\\\n",
    "x \\left(\\frac{x+3}{6}\\right) & \\text{иначе}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-3.3526,  3.1458, -2.0256,  1.7843])\n",
      "Выходные данные: tensor([-0.0000,  3.1458, -0.3290,  1.4228])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Hardswish\n",
    "g = nn.Hardswish()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-3.3526, 3.1458, -2.0256, 1.7843]) # torch.randn(4)\n",
    "\n",
    "# Применение функции активации Hardswish к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mish\n",
    "\n",
    "> Преобразование значений, комбинируя значения $x$ с их $softplus$-преобразованиями ($\\text{Softplus}(x) = \\frac{1}{\\beta} \\log(1 + \\exp(\\beta \\times x))$) и примененым гиперболическим тангенсом\n",
    "\n",
    "$$\n",
    "\\text{Mish}(x) = x \\times \\tanh(\\text{Softplus}(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([-0.2132,  1.0198])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Mish\n",
    "g = nn.Mish()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации Mish к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softplus\n",
    "\n",
    "> Преобразование значений, сглаживая их, обеспечивая плавный переход между линейными и нелинейными областями, контролируемый параметром $\\beta$\n",
    "\n",
    "$$\n",
    "\\text{Softplus}(x) = \\frac{1}{\\beta} \\log(1 + \\exp(\\beta \\times x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458])\n",
      "Выходные данные: tensor([0.0909, 1.4219])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Softplus\n",
    "g = nn.Softplus(beta = 1.0, threshold = 20.0)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458]) # torch.randn(2)\n",
    "\n",
    "# Применение функции активации Softplus к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softshrink\n",
    "\n",
    "> Преобразование значений, уменьшая их на величину $\\lambda$ и устанавливая их в ноль, если значения по абсолютной величине меньше $\\lambda$\n",
    "\n",
    "$$\n",
    "\\text{Softshrink}(x) = \n",
    "\\begin{cases} \n",
    "x - \\lambda & \\text{если } x > \\lambda \\\\\n",
    "x + \\lambda & \\text{если } x < -\\lambda \\\\\n",
    "0 & \\text{иначе}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458,  0.4320, -0.3791])\n",
      "Выходные данные: tensor([-1.8526,  0.6458,  0.0000,  0.0000])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Softshrink\n",
    "g = nn.Softshrink(lambd = 0.5)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458, 0.4320, -0.3791]) # torch.randn(4)\n",
    "\n",
    "# Применение функции активации Softshrink к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softsign\n",
    "\n",
    "> Преобразование значений, уменьшая их величину, где входные значения делятся на сумму 1 и их абсолютного значения\n",
    "\n",
    "$$\n",
    "\\text{Softsign}(x) = \\frac{x}{1 + |x|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458,  0.4320, -0.3791])\n",
      "Выходные данные: tensor([-0.7017,  0.5340,  0.3017, -0.2749])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Softsign\n",
    "g = nn.Softsign()\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458, 0.4320, -0.3791]) # torch.randn(4)\n",
    "\n",
    "# Применение функции активации Softsign к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold\n",
    "\n",
    "> Преобразование значений, при котором значения, большие заданного порога ($threshold$) остаются без изменений, а значения, меньшие порога, заменяются на заданное значение ($value$)\n",
    "\n",
    "$$\n",
    "\\text{Threshold}(x) = \n",
    "\\begin{cases}\n",
    "x & \\text{если } x > threshold \\\\\n",
    "value & \\text{иначе}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([-2.3526,  1.1458,  0.4320, -0.3791])\n",
      "Выходные данные: tensor([20.0000,  1.1458,  0.4320, 20.0000])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта Threshold\n",
    "g = nn.Threshold(threshold = 0.1, value = 20)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([-2.3526, 1.1458, 0.4320, -0.3791]) # torch.randn(4)\n",
    "\n",
    "# Применение функции активации Threshold к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLU (Gated Linear Unit)\n",
    "\n",
    "> Преобразование значений, при котором данные разделяется на две половины по последнему размеру, первая половина остается неизменной, а ко второй применяется сигмоидная функция, и перемножение этих частей дает результат\n",
    "\n",
    "$$\n",
    "\\text{GLU}(x) = x_1 \\times \\sigma(x_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные: tensor([[-0.0915,  0.2352],\n",
      "        [ 2.2440,  0.5817],\n",
      "        [ 0.4528,  0.6410],\n",
      "        [ 0.5200,  0.5567]])\n",
      "Выходные данные: tensor([[-0.0511],\n",
      "        [ 1.4394],\n",
      "        [ 0.2966],\n",
      "        [ 0.3306]])\n"
     ]
    }
   ],
   "source": [
    "# Создание объекта GLU\n",
    "g = nn.GLU(dim = -1)\n",
    "\n",
    "# Генерация случайного тензора\n",
    "input = torch.tensor([\n",
    "    [-0.0915,  0.2352],\n",
    "    [ 2.2440,  0.5817],\n",
    "    [ 0.4528,  0.6410],\n",
    "    [ 0.5200,  0.5567]\n",
    "]) # torch.randn(4, 2)\n",
    "\n",
    "# Применение функции активации GLU к входным данным\n",
    "output = g(input)\n",
    "\n",
    "# Вывод входных и выходных данных\n",
    "print(\"Входные данные:\", input)\n",
    "print(\"Выходные данные:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiheadAttention\n",
    "\n",
    "> Преобразование значений, используя механизм многоголового внимания, где входные $query$, $key$ и $value$ проходят через несколько голов внимания, объединяются и линейно преобразуются в окончательный результат\n",
    "\n",
    "$$\n",
    "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W^O \\quad \\text{где } \\text{head}_i = \\text{Attention}(Q W_i^Q, K W_i^K, V W_i^V)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат внимания: tensor([[[ 0.3506, -0.4100,  0.2552],\n",
      "         [ 0.3011, -0.3505,  0.1884]],\n",
      "\n",
      "        [[ 0.3484, -0.4180,  0.3896],\n",
      "         [ 0.3647, -0.4350,  0.3933]],\n",
      "\n",
      "        [[ 0.6635, -0.7905,  0.5281],\n",
      "         [ 0.5572, -0.6717,  0.4763]]], grad_fn=<TransposeBackward0>)\n",
      "Веса внимания: tensor([[[0.5456, 0.4544],\n",
      "         [0.6605, 0.3395]],\n",
      "\n",
      "        [[0.4327, 0.5673],\n",
      "         [0.4727, 0.5273]],\n",
      "\n",
      "        [[0.7918, 0.2082],\n",
      "         [0.6547, 0.3453]]], grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Параметры\n",
    "embed_dim = 3 # Размерность эмбеддинга\n",
    "num_heads = 1 # Количество голов\n",
    "\n",
    "# Создание объекта MultiheadAttention\n",
    "multihead_attn = nn.MultiheadAttention(\n",
    "    embed_dim = embed_dim,\n",
    "    num_heads = num_heads,\n",
    "    dropout = 0.0,\n",
    "    bias = True,\n",
    "    add_bias_kv = False,\n",
    "    batch_first = True\n",
    ")\n",
    "\n",
    "# Генерацие случайных тензоров для query, key и value\n",
    "query = torch.tensor([\n",
    "    [\n",
    "        [-1.4025,  0.4318,  0.3431],\n",
    "        [ 1.0711,  1.3455,  0.3277]],\n",
    "    [\n",
    "        [ 1.3409,  1.2159,  0.9589],\n",
    "        [ 0.5137,  0.4977, -0.6646]],\n",
    "    [\n",
    "        [-1.0612,  2.0423,  0.6509],\n",
    "        [-1.0072,  0.3578, -1.0799]\n",
    "    ]\n",
    "]) # (batch size, target sequence length, embed_dim)\n",
    "key = torch.tensor([\n",
    "    [\n",
    "        [-1.4025,  0.4318,  0.3431],\n",
    "        [ 1.0711,  1.3455,  0.3277]],\n",
    "    [\n",
    "        [ 1.3409,  1.2159,  0.9589],\n",
    "        [ 0.5137,  0.4977, -0.6646]],\n",
    "    [\n",
    "        [-1.0612,  2.0423,  0.6509],\n",
    "        [-1.0072,  0.3578, -1.0799]\n",
    "    ]\n",
    "]) # (batch size, source sequence length, embed_dim)\n",
    "value = torch.tensor([\n",
    "    [\n",
    "        [-1.4025,  0.4318,  0.3431],\n",
    "        [ 1.0711,  1.3455,  0.3277]],\n",
    "    [\n",
    "        [ 1.3409,  1.2159,  0.9589],\n",
    "        [ 0.5137,  0.4977, -0.6646]],\n",
    "    [\n",
    "        [-1.0612,  2.0423,  0.6509],\n",
    "        [-1.0072,  0.3578, -1.0799]\n",
    "    ]\n",
    "]) # (batch size, source sequence length, embed_dim)\n",
    "\n",
    "# Применение функции активации MultiheadAttention к входным данным\n",
    "# attn_output = (batch size, target sequence length, embed_dim)\n",
    "# attn_output_weights = (batch size, target sequence length, source sequence length)\n",
    "attn_output, attn_output_weights = multihead_attn(query, key, value)\n",
    "\n",
    "# Выходных данных\n",
    "print(\"Результат внимания:\", attn_output)\n",
    "print(\"Веса внимания:\", attn_output_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
