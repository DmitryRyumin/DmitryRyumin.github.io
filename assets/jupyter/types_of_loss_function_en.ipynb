{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Version of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings(\"ignore\", category = warn)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import jupyterlab as jlab\n",
    "\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versions of Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>#</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Torch</td>\n",
       "      <td>2.2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NumPy</td>\n",
       "      <td>1.26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pandas</td>\n",
       "      <td>2.2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JupyterLab</td>\n",
       "      <td>4.2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Package Version\n",
       "#                    \n",
       "1       Torch   2.2.2\n",
       "2       NumPy  1.26.4\n",
       "3      Pandas   2.2.2\n",
       "4  JupyterLab   4.2.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "packages = [\n",
    "    \"Torch\", \"NumPy\", \"Pandas\", \"JupyterLab\",\n",
    "]\n",
    "\n",
    "package_objects = [\n",
    "    torch, np, pd, jlab\n",
    "]\n",
    "\n",
    "versions = [obj.__version__ for obj in package_objects]\n",
    "\n",
    "pkgs = {\"Package\": packages, \"Version\": versions}\n",
    "df_pkgs = pd.DataFrame(data = pkgs)\n",
    "df_pkgs.index.name = \"#\"\n",
    "df_pkgs.index += 1\n",
    "\n",
    "display(df_pkgs)\n",
    "\n",
    "path_to_reqs = \".\"\n",
    "reqs_name = \"requirements.txt\"\n",
    "\n",
    "def get_packages_and_versions():\n",
    "    \"\"\"Generate strings with libraries and their versions in the format: package==version\"\"\"\n",
    "    \n",
    "    for package, version in zip(packages, versions):\n",
    "        yield f\"{package.lower()}=={version}\\n\"\n",
    "\n",
    "with open(os.path.join(path_to_reqs, reqs_name), \"w\", encoding = \"utf-8\") as f:\n",
    "    f.writelines(get_packages_and_versions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1Loss (L1-Norm or Mean Absolute Error)\n",
    "\n",
    "`Regression`\n",
    "\n",
    "> Measures the mean absolute difference between the predicted and true values of the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.100000023841858\n",
      "Gradients on input data: tensor([[ 0.1667, -0.1667,  0.1667],\n",
      "        [ 0.0000, -0.1667,  0.1667]])\n"
     ]
    }
   ],
   "source": [
    "# Create a L1Loss object\n",
    "loss = nn.L1Loss(reduction = \"mean\") # none | mean | sum\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[0.5, -0.3, 1.2], [0.0, -1.5, 2.1]], requires_grad = True) # torch.randn(2, 3)\n",
    "target = torch.tensor([[0.0, 0.0, 1.0], [0.0, 1.0, -1.0]]) # torch.randn(2, 3)\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input, target)\n",
    "\n",
    "print(\"Mean Absolute Error:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSELoss (Mean Squared Error Loss)\n",
    "\n",
    "`Regression`\n",
    "\n",
    "> Measure the Mean Squared Error between the predicted and true values of the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.706666946411133\n",
      "Gradients on input data: tensor([[ 0.1667, -0.1000,  0.0667],\n",
      "        [ 0.0000, -0.8333,  1.0333]])\n"
     ]
    }
   ],
   "source": [
    "# Create a MSELoss object\n",
    "loss = nn.MSELoss(reduction = \"mean\") # none | mean | sum\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[0.5, -0.3, 1.2], [0.0, -1.5, 2.1]], requires_grad = True) # torch.randn(2, 3)\n",
    "target = torch.tensor([[0.0, 0.0, 1.0], [0.0, 1.0, -1.0]]) # torch.randn(2, 3)\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input, target)\n",
    "\n",
    "print(\"Mean Squared Error:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoissonNLLLoss\n",
    "\n",
    "`Regression`\n",
    "\n",
    "> Measures the negative logarithmic likelihood of the predicted values, assuming the target labels follow a Poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: 2.916492462158203\n",
      "Gradients on input data: tensor([[ 0.2748,  0.1235,  0.3867],\n",
      "        [ 0.1667, -0.1295,  1.5277]])\n"
     ]
    }
   ],
   "source": [
    "# Create a PoissonNLLLoss object\n",
    "loss = nn.PoissonNLLLoss(log_input = True, full = False, eps = 1e-8, reduction = \"mean\")\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[0.5, -0.3, 1.2], [0.0, -1.5, 2.1]], requires_grad = True) # torch.randn(2, 3)\n",
    "target = torch.tensor([[0.0, 0.0, 1.0], [0.0, 1.0, -1.0]]) # torch.randn(2, 3)\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input, target)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNLLLoss\n",
    "\n",
    "`Regression`\n",
    "\n",
    "> Measures the negative logarithmic likelihood of the predicted values and variance, assuming the target labels follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: -0.39910173416137695\n",
      "Gradients on input data: tensor([[-0.1667,  0.0000],\n",
      "        [ 0.0000, -0.5556],\n",
      "        [ 0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Create a GaussianNLLLoss object\n",
    "loss = nn.GaussianNLLLoss(full = False, eps = 1e-6, reduction = \"mean\")\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[2.5, 0.0], [0.0, 1.0], [1.0, 2.0]], requires_grad = True)\n",
    "target = torch.tensor([[3.0, 0.0], [0.0, 2.0], [1.0, 2.0]])\n",
    "var = torch.tensor([[0.5, 0.2], [0.1, 0.3], [0.2, 0.3]])\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input, target, var)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KLDivLoss (Kullback-Leibler Divergence Loss)\n",
    "\n",
    "`Regression`\n",
    "\n",
    "> Measure the Kullback-Leibler divergence between two probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: 0.1021953895688057\n",
      "Gradients on input data: tensor([[ 0.0947, -0.0401, -0.0547],\n",
      "        [ 0.0246, -0.0991,  0.0746]])\n"
     ]
    }
   ],
   "source": [
    "# Create a LogSoftmax object\n",
    "m = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "# Create a KLDivLoss object\n",
    "loss = nn.KLDivLoss(reduction = \"batchmean\")\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[0.2, 0.3, 0.5], [0.1, 0.8, 0.1]], requires_grad = True)\n",
    "target = torch.tensor([[0.1, 0.4, 0.5], [0.2, 0.7, 0.1]])\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(m(input), target)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CrossEntropyLoss\n",
    "\n",
    "`Classification`\n",
    "\n",
    "> A combination of **LogSoftmax** and **NLLLoss (Negative Log Likelihood Loss)** to measure the difference between predicted class probabilities and true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: 0.47952529788017273\n",
      "Gradients on input data: tensor([[ 0.0450,  0.1224, -0.1674],\n",
      "        [ 0.1060, -0.2119,  0.1060]])\n"
     ]
    }
   ],
   "source": [
    "# Create a CrossEntropyLoss object\n",
    "loss = nn.CrossEntropyLoss(reduction = \"mean\", label_smoothing = 0.0) # none | mean | sum\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 1.0]], requires_grad = True) # torch.randn(2, 3)\n",
    "target = torch.tensor([2, 1])\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input, target)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLLLoss\n",
    "\n",
    "`Classification`\n",
    "\n",
    "> Measure the difference between the predicted class probabilities (after applying **LogSoftmax**) and the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: 0.47952529788017273\n",
      "Gradients on input data: tensor([[ 0.0450,  0.1224, -0.1674],\n",
      "        [ 0.1060, -0.2119,  0.1060]])\n"
     ]
    }
   ],
   "source": [
    "# Create a LogSoftmax object\n",
    "m = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "# Create a NLLLoss object\n",
    "loss = nn.NLLLoss(reduction = \"mean\") # none | mean | sum\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[1.0, 2.0, 3.0], [1.0, 2.0, 1.0]], requires_grad = True) # torch.randn(2, 3)\n",
    "target = torch.tensor([2, 1])\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(m(input), target)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCELoss (Binary Cross Entropy Loss)\n",
    "\n",
    "`Binary Classification`\n",
    "\n",
    "> Measure the difference between predicted probabilities and true binary labels using a cross-entropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: 0.3190375566482544\n",
      "Gradients on input data: tensor([[-0.4167],\n",
      "        [ 0.4167],\n",
      "        [-0.5556]])\n"
     ]
    }
   ],
   "source": [
    "# Create a BCELoss object\n",
    "loss = nn.BCELoss(reduction = \"mean\") # none | mean | sum\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[0.8], [0.2], [0.6]], requires_grad = True)\n",
    "target = torch.tensor([[1.0], [0.0], [1.0]])\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input, target)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCEWithLogitsLoss\n",
    "\n",
    "`Binary Classification`\n",
    "\n",
    "> Measures the difference between predicted logits and true binary labels, combining sigmoid and binary cross-entropy calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: 0.36532461643218994\n",
      "Gradients on input data: tensor([[-0.0608],\n",
      "        [ 0.0608],\n",
      "        [-0.1667]])\n"
     ]
    }
   ],
   "source": [
    "# Create a BCEWithLogitsLoss object\n",
    "loss = nn.BCEWithLogitsLoss(reduction = \"mean\") # none | mean | sum\n",
    "\n",
    "# Generate input data and target labels\n",
    "input = torch.tensor([[1.5], [-1.5], [0.0]], requires_grad = True)\n",
    "target = torch.tensor([[1.0], [0.0], [1.0]])\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input, target)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MarginRankingLoss\n",
    "\n",
    "`Ranking`\n",
    "\n",
    "> Ranking of pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function value: 0.46666666865348816\n",
      "Gradients on input data: tensor([[-0.0608],\n",
      "        [ 0.0608],\n",
      "        [-0.1667]])\n"
     ]
    }
   ],
   "source": [
    "# Create a MarginRankingLoss object\n",
    "loss = nn.MarginRankingLoss(reduction = \"mean\") # none | mean | sum\n",
    "\n",
    "# Generate input data and target labels\n",
    "input1 = torch.tensor([0.8, 0.7, -0.2], requires_grad = True)\n",
    "input2 = torch.tensor([0.1, -0.1, 0.5], requires_grad = True)\n",
    "target = torch.tensor([1, 2, 2])\n",
    "\n",
    "# Calculating the Loss Function\n",
    "output = loss(input1, input2, target)\n",
    "\n",
    "print(\"Loss function value:\", output.item())\n",
    "\n",
    "# Backpropagation\n",
    "output.backward()\n",
    "\n",
    "print(\"Gradients on input data:\", input.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
